---
title: "Appendix: Bayesian model of COVID-19 mortality risk in HCT volunteers"
author: "Witold WiÄ™cek for 1 Day Sooner"
date: "Last updated `r Sys.Date()`"
output: 
  pdf_document:
    keep_tex: true
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(baggr)
library(tidyverse)
library(readxl)
library(knitr)
library(kableExtra)
# Stan stuff:
library(rstan)
set.seed(1990)
rstan_options(auto_write = TRUE)
sm <- stan_model("ifr_with0.stan")
options(mc.cores = 4, digits = 2)
```


# Introduction

This short document is a technical appendix to the paper discussing COVID-19 risks in human challenge trial. Here, we show how a Bayesian model can synthesise information on many infection fatality rates (IFRs) into a single estimate. This estimate is  specific to certain age groups and can be further adjusted by e.g. co-morbidity status. The analysis presented here is a form of Bayesian meta-analysis , in that our primary objective is to weigh sources of evidence in a way that captures both variability (here, heterogeneity in real IFRs across different settings) and uncertainty (here, the fact that we do not know the IFRs in each setting precisely).

The ultimate objective of this model is to  characterise risk in a way that is useful for design of HCTs. Therefore, as a minimum, we want to incorporate variability across different populations into our prediction. Even better would be to understand how different factors can drive heterogeneity: _a priori_ we hypothesise that the three main drivers of differences in IFRs are time-specific, population-specific and otherwise country-specific.^[The role of time may be due to new treatments, improvements over time in our ability to treat Covid-19 or selection pressures which may lead to more benign versions of the virus. Country-specific or location-specific factors in IFR data may be driven by under-reporting, health care factors (including access to health care services) or underlying distributions of known risk factors. Additionally, some unknown risk factors (e.g. genetic) may also be operating, in which case controlling for age and co-morbidities will be not sufficient to account for cross-location differences.]

To characterise differences in observed IFRs we first develop a Bayesian model and apply it to publicly available summary data on IFRs from multiple countries and contexts, with particular focus on the impact of age. This is covered by Section 2. We then use a simple model to hypothesise reduction in risk that may be achieved by screening individuals for comorbidities; this is Section 3. We summarise all results in Section 4.


# Age-specific risk of COVID-19 mortality

## Bayesian evidence synthesis model

What follows is an adaptation of typical methods of Bayesian evidence synthesis to analysis of IFRs. IFR is the ratio of deaths to infections in a given population. Early estimates of Covid-19 mortality risk, e.g. by @verity_estimates_2020, placed it at over 0.6%; however, it was also evident from data that IFR could be orders of magnitude higher in particular high risk groups, especially in the elderly, than in the general population.^[Various estimates published since suggested that the relationship of mortality risk to age is consistent across different countries.]

By definition, our data on IFRs is a combination of data on deaths with data on infections. Typically, these are disjoint samples, in that numbers of infections are estimated (typically very imprecisely) on select subpopulation, while deaths are recorded in the general population (at a level of country, administrative region etc.). There are clear reasons to believe that IFRs will differ across studies (e.g. due to age, comorbidity status, time, genetic factors, quality of healthcare etc.). To address this, we will use a Bayesian hierarchical modelling framework to assume that the setting-specific estimates of $IFR_k$ can differ from each other but are linked through some common parameters. (By $k$'s we denote different populations; note that sometimes we may have multiple $IFR$'s from different age groups in the same location.)

The most straight-forward and "canonical" way to implement such a Bayesian model is by modelling log odds of the event.^[It is also possible to work with $IFR_k$ parameters and treat them as derived from Beta distribution with some "hyperparameters" $\alpha$ and $\beta$ of Beta distribution, as done by e.g. @carpenter_hierarchical_2016. That approach, however, does not offer an easy way of modelling impact of covariates (e.g. age and co-morbidities) on the rates.]
@deeks_issues_2002 present a general treatment of such approach in medical statistics. Note, that for very rare events the odds of mortality are very similar to probability of mortality, but we model events on odds scale as a good "generic" approach to modelling binary data (in this case death following infections).^[Another advantage of such a model is that it can use either individual-level or summary data and work with covariates (such as gender, age, time of the study, co-morbidities), captured as odds ratios or risk ratios. If only summary data are available, covariates can be defined as study level distributions (e.g. % male)]

Basic models for this type of analysis of binary data can be implemented using existing statistical analysis packages (see, for example, _metafor_ package in R or _baggr_  by @wiecek_baggr_2020), by treating IFR as a logit-normal parameter to meta-analyse. However, note that when no deaths are observed, analysis of IFR (equal to observed deaths divided by modelled infections) is problematic. Therefore we propose a "custom" model that built in Stan which treats deaths and _prevalences_ (rather than the IFRs) as data. 

Let $d_k$ denote observed deaths for data point $k$ and assume that logit of corresponding prevalence estimate is $p_k$ is a parameter (typically obtained from a statistical modelling papers, government reports etc.). Total population in $k$-th setting is $n_k$. Total number of estimates is $K$. Then the model likelihood is as follows:

\begin{align}
d_k & \sim \text{Binomial}(n_k, p_kIFR_k) \\
\text{logit}(p_k) & \sim \mathcal{N}(\mu^{(p)}_k, (\sigma^{(p)}_k)^2)
\end{align}

where $\sigma^{(p)}_k$ and $\mu^{(p)}_k$ are parameters obtained from the literature (or converted from these parameters -- see next section). The $k$ data points collected can span many locations (studies); we denote them by $\text{loc}_k$ and the total number of locations by $K_{loc}$ (with $K_{loc} < K$).

In this model we can also account for various covariates impacting the IFRs (let's denote their total number by $N_p$), such as age groups (which we identify with median age of the population being studied, $\text{MedianAge}_k$). We code them in a design matrix $X$. To center our $X$ at the value of interest in our model (risk in 20-30 year olds), we use a transformation `MedianAge/10 - 2.5` to construct our matrix $X$. We denote all of the covariates using a design matrix $X$ and denote by $N_p$ the number of columns in $X$. 
We assume the impact on IFR is on logit scale, same as in the "canonical" logistic models of binary data that we mentioned above:

\begin{align}
\text{logit}(IFR_k) &= \theta_{\text{loc}_k} + X\beta, \\
\theta_j & \sim \mathcal{N}(\tau, \sigma^2), \bigskip \text{where } j=1,\ldots,K_{loc}.
\end{align}

This means $\theta$ spans location-specific (random) effects on IFR while $\beta$ is $N_p$ dimensional vector of (fixed) covariate effects.

We implement our model in Stan and assume weakly informative priors on all parameters, with prior for $\tau$ centered at 1 death per 10,000 cases. 

```
model {
  //Uncertain prevalence estimates (mu^p and sigma^p above):
  logit_prevalence ~ normal(mean_prevalence, sd_prevalence);
  //Likelihood of mortality (d_k = obs_deaths, p_k = prevalence):
  obs_deaths ~ binomial(population, prevalence .* ifr);
  //Hierarchical component of the model (location-specific theta):
  //logit_ifr = theta_k[loc] + to_vector(X*beta);
  theta_k ~ normal(tau, sigma);

  //Priors:
  tau   ~ normal(logit(.0001), 5);
  sigma ~ normal(0, 10);
  beta  ~ normal(0, 10);
}
```







## Data 

```{r read-data, eval = F}
# Several different datasets.
NBER_IFR_Benchmark_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xlsx',1)
#Places: Belgium. Geneva, Indiana, New York, Spain, Sweden
NBER_IFR_US_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xlsx',2, skip=1)
names(NBER_IFR_US_Studies)[6:7]<-c('Infect 95_lower','Infect 95_upper')
names(NBER_IFR_US_Studies)[10:11]<-c('IFR_95_lower','IFR_95_upper')

# NBER_All_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xls',5)
```

```{r read-joint-data}
all_data_xls <- read_excel("data/1DS_Meta_Dataset_ww.xls") %>%
                           # col_types = c("text", "text", "date", "date", rep("text", 4), "numeric", "text", rep("numeric", 11))) %>%
  rename(Study = StudyName) %>%
  # Use imputed deaths and population sizes where neeeded
  mutate(Deaths = ifelse(is.na(Deaths) & !is.na(`Imputed Deaths`), `Imputed Deaths`, Deaths)) %>%
  mutate(Population = ifelse(is.na(Population) & !is.na(`Imputed Population`), `Imputed Population`, Population))
```


```{r}
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))

ifr_joint <- all_data_xls %>%
  group_by(Study) %>%
  mutate(ir = InfectionRate/100, 
         ir_low = infrate_ci95_low/100, 
         ir_high = infrate_ci95_high/100) %>%
  select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
  mutate(dataset = "Global")

# ifr_global <- NBER_IFR_Benchmark_Studies %>%
#   group_by(Study) %>%
#   mutate(ir = InfectionRate/100, 
#          ir_low = infrate_ci95_low/100, 
#          ir_high = infrate_ci95_high/100) %>%
#   select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
#   mutate(dataset = "Global")
# 
# ifr_us <- NBER_IFR_US_Studies %>%
#   filter(!is.na(AgeGroup)) %>%
#   group_by(Study) %>%
#   mutate(ir = `Infection Rate (%)`/100, 
#          ir_low = `Infect 95_lower`/100, 
#          ir_high = `Infect 95_upper`/100) %>%
#   select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
#   mutate(dataset = "United States")
```



```{r prep-data}
# df <- rbind(ifr_global, ifr_us) %>%
df <- ifr_joint %>%
  mutate(logit_sd = ifelse(ir_low != 0, 
                         (logit(ir_high) - logit(ir_low))/(2*1.96), 
                         (logit(ir_high) - logit(ir))/1.96)) %>%
  mutate(logit_mean = logit(ir)) %>%
  filter(!is.na(Deaths), !is.na(logit_sd), !is.na(logit_mean), !is.na(Population))
```

```{r}
df_age <- df %>% mutate(age = gsub("\\+", "-Inf", AgeGroup)) %>%
  separate(age, c("ageMin", "ageMax")) %>%
  select(Study, ageMin, ageMax) 
good_data_pts <- sum(df_age$ageMin < 30 & df_age$ageMax > 20)
```

We used estimates originally collected by @levin_assessing_2020 to construct the first version of analysis dataset, which we then supplemented with more values extracted from other studies. __Write-up of data collection here OR REFERENCE DATA COLLECTION ELSEWHERE.__ The input data into our model consists of deaths (treated as known) and prevalences (treated as logit-distributed parameter with known mean and SD) in all reported age groups in all studies^[This basic approach exaggerates uncertainty, as we treat different 95% intervals reported in the study as uncorrelated.]. 

```{r}
data_ns <- df %>% group_by(Study) %>% tally() %>% pull(n)
```

All of input data are given in Table \@ref(tab:input-data-big). The analysis dataset contains `r nrow(df)` data points from `r length(data_ns)` studies, each containing between `r min(data_ns)` and `r max(data_ns)` different age groups. We made only minimal modifications to source data, by 1) imputing the values from the Italian fatality data based on a seroprevalence survey, 2) imputing population size in Maranhao (as ratio of the reported number of infections and the mean infection rate) which were not reported and 3) assuming that uncertainty in prevalence 0-29 age group in Iceland is same as in the 30-39 age group since data were missing.

As mentioned, our model treats number of Covid-attributable deaths as measured without error (due to lack of data) but accounts for uncertainty in infection rates, which are always model-based estimates extracted from various available data sources. In preparing data, we assumed that logits of prevalence estimates from available studies are normally distributed, which seems to reproduce majority of data very well, see Figure \@ref(fig:prevalence-data) in the Supplement. There are some discrepancies with studies that allowed for prevalence estimates to be 0, something that our logit model does not allow.

For each study we construct a median age scalar defined by the average of the endpoints of each age range, rather than attempting to calculate a population-weighted mean.

Our approach of regressing on the median age and use of all available data (rather than the subset of data available in younger adults only) is necessitated by data limitations: out of `r nrow(df_age)` data points comprising age-specific estimates of prevalence (or IFR) and counts of deaths, `r good_data_pts` contain individuals aged 20-30 who are of primary interest to us. However, the populations are mixed with regards to age, with typical age groupings such as 19-49, 20-49, 20-39, 0-49 used instead. In fact, we find only one estimate out of `r good_data_pts` that is entirely specific to the 20-29 age group (Brazilian state of Maranhao), while one more has median age falling between 20 and 30 but is not specific to that age group.

```{r stan-data}
mm <- model.matrix(ir ~ Study + Median_Age, data = df)
stan_data <- list(
  X = matrix(df$Median_Age/10 - 2.5, nrow(df), 1),
  N = nrow(df), 
  Np = 1,
  Nloc = length(unique(df$Study)),
  loc = as.numeric(as.factor(df$Study)),
  mean_prevalence = df$logit_mean,
  sd_prevalence = df$logit_sd,
  population = as.integer(df$Population),
  obs_deaths = as.integer(df$Deaths))
```


## Results


```{r run-stan-model, eval = FALSE}
fit <- sampling(sm, data = stan_data, control = list(max_treedepth = 15), 
                iter = 5000, refresh = 0,
                pars = c("logit_ifr", "logit_prevalence"), include = FALSE)
saveRDS(fit, file = "output/main_stan_model.rds")
```

```{r}
fit <- readRDS("output/main_stan_model.rds")
```

There were no issues with convergence of the Bayesian model. We set number of iterations to 5,000 and used 4 chains, with `max_treedepth` option set to 15. There were no divergent transitions and effective sample size was greater than `r round(min(summary(fit)$summary[,"n_eff"]))` for all of `r length(summary(fit)$summary[,"n_eff"]) - 1` modeled parameters (this number includes fitted prevalences, IFRs, $\theta$'s and their transformations into/from logit scales). For the three main parameters in the model we obtained the following:

```{r}

print(fit, c("tau", "sigma", "beta"))
```

The mean coefficient of beta `r round(mean(c(as.matrix(fit, "beta[1]"))), 2)` corresponds to `r mean(exp(mean(c(as.matrix(fit, "beta[1]")))))`-fold increase in mortality risk following an infection per each extra decade of age (95% uncertainty interval is `r paste(round(quantile(exp((c(as.matrix(fit, "beta[1]")))), c(.025, .975)),2),collapse = "-")`).

From these parameters we can predict average risks for subjects of any given age $x$, by using the posterior distribution of $\tau + (10x + 2.5) \beta$ (where 2.5 and 10 refer to the transformation that we applied to `MedianAge` inputs).



## Average infection fatality risk in young subjects

```{r}
hypermean    <- (rstan::extract(fit, "tau")[[1]])
hypersd      <- (rstan::extract(fit, "sigma")[[1]])
beta         <- (rstan::extract(fit, "beta")[[1]])
nsamples     <- length(hypermean)
hyperifr     <- inv_logit(hypermean)
replications <- inv_logit(rnorm(nsamples, hypermean, hypersd))
```

Since we centered our `MedianAge` at 25 years in constructing our matrix $X$, we can now obtain model-estimated risk for a typical HCT population (aged 20 to 30, with median 25) by ignoring the $\beta$ coefficient and examining $\tau$ and $\sigma$ only. We find that the average IFR for this group (equal to $\frac{\exp{(\tau)}}{\exp{(1 + \tau)}}$) is `r mean(hyperifr)` (with 95% interval from `r quantile(hyperifr, .025)` to `r quantile(hyperifr, .975)`). That means, on average, slightly under 2 deaths per 10,000 infections in the studied datasets.


### Heterogeneity in IFRs

However, there is a considerable variability in IFRs across different locations/dataset that we should consider. To take into account parameter $\sigma$, we can generate draws from the $\mathcal{N}(\tau, \sigma^2)$ distribution, corresponding to a hypothetical IFR in a new source of data. 95% interval for such model runs from `r quantile(replications, .025)` to `r quantile(replications, .975)`. Since the model works a logistic scale, another way of interpreting the across-dataset variability is reporting the fold-impact of $\sigma$ on the mean IFR; here, we obtain on average a `r mean(exp(2*hypersd))`-fold increase (decrease) in IFR per $2\sigma$ increase (decrease).

The lower end of the 95% interval, `r quantile(replications, .025)`, is not extreme given input data, where the "crude" mean IFR (based on mean prevalence only) is below 7 per 10,000 for all data except for South Florida, and as low as 0 for some countries that did not record deaths (Belgium, New Zealand, Korea, Iceland) in various age groups including 20-29 year olds or 1.4 per 10,000 in Utah, in the population aged 19-44. (Please refer to Table \@ref(tab:input-data-big) for complete list of inputs.)

```{r, eval = FALSE}
df %>% filter(Median_Age > 10, Median_Age < 35) %>% 
  select(Study, AgeGroup, Deaths, Population, ir) %>%
  mutate(crude_ifr = Deaths/(Population*ir))
```

```{r}
theta_mean <- summary(fit, "theta_k")$summary[,"mean"]
names(theta_mean) <- levels(as.factor(df$Study))
```

We can assess this heterogeneity by inspecting the distribution of random effects in the model transformed into IFRs, 
i.e. the inverse logit transformation $\theta$ parameters. 
The largest (posterior mean) IFR value of $\theta$ is `r inv_logit(max(theta_mean))` in `r names(theta_mean)[which.max(theta_mean)]`.
The smallest posterior mean for 20-29 year olds is `r inv_logit(min(theta_mean))` in `r names(theta_mean)[which.min(theta_mean)]`.



### Predictive checks for the model

```{r}
df_cov <- data.frame(study = df$Study, 
           observed = df$Deaths,
           summary(fit, "ppc_deaths")$summary) %>% 
  mutate(coverage975 = (observed + .1) > X2.5. & observed < X98.) %>%
  mutate(coverage50 = (observed + .1) > X25. & observed < X75.) %>% 
  summarise(n = n(), coverage975 = sum(coverage975), coverage50 = sum(coverage50))
```

We constructed posterior predictive distributions for number of deaths in each of the inputs by using the `generated quantities` functionality of Stan. Figure \@ref(fig:obs-est-deaths) compares the posterior means and 95% intervals with observed deaths. Out of `r df_cov$n` observations that were used to fit the model, `r df_cov$coverage975` were within 95% intervals of the posterior predictive distributions. We observed the largest discrepancies occurred in Spanish data. Overall, we conclude that the simple binomial model we used here is flexible enough to capture both age-specific risk increases and heterogeneity in IFRs across settings/countries. 

```{r obs-est-deaths, fig.width = 10, fig.height = 10, fig.cap = "Comparison of model estimates (black) with data on observed fatality rate (FR, red), compared on logarithmic scale. FR is number of deaths divided by overall population size. Bars are 95% posterior interval; point is the mean. For better clarity, we grouped the plot into four panels according to observed FR X axes on each panel differ. For many low-risk populations (upper-left quadrant) no deaths were reported: we indicate this by plotting a red point on the left-hand side of the panel plot.", warning = FALSE}
data.frame(study = df$Study, 
           age = df$AgeGroup,
           observed = df$Deaths,
           summary(fit, "ppc_deaths")$summary) %>% 
  mutate_if(is.numeric, function(x) x/df$Population) %>%
  mutate(deaths_cut = cut(observed, c(-Inf, 1/1e06, 50/1e06, 500/1e06, Inf),
                          c("< 1 per million", "1-50 per million", "50-500 per million", "over 500 per million"))) %>%
  ggplot(aes(y=interaction(study, age))) + 
  geom_point(aes(x = mean)) + 
  geom_errorbarh(aes(xmin = X2.5., xmax = X98.)) + 
  geom_point(aes(x = observed), color = "red") + 
  facet_wrap(~deaths_cut, ncol = 2, scales = "free") +
  scale_x_log10() +
  xlab("Covid-attributable fatality rate") + ylab("")
```

```{r}
hypermean <- (rstan::extract(fit, "tau")[[1]])
hypersd <- (rstan::extract(fit, "sigma")[[1]])
beta <-  (rstan::extract(fit, "beta[1]")[[1]])


hyperifr <- inv_logit(hypermean)
replications <- inv_logit(rnorm(nsamples, hypermean, hypersd))

df_rep <- data.frame(age = rep(seq(1, 85), each = 5e04)) %>%
  mutate(hypermean = sample(hypermean, nrow(.), replace = T),
         hypersd = sample(hypersd, nrow(.), replace = T),
         beta = sample(beta, nrow(.), replace = T)) %>%
  mutate(mean_draw = hypermean + beta*(age/10 - 2.5)) %>%
  mutate(rep_draw  = rnorm(nrow(.), mean_draw, hypersd)) %>%
  select(age, mean_draw, rep_draw)

mint <- function(x) c(quantile(x, .025), mean(x), quantile(x, .975))
mint_nm <- c("q025", "mean", "q975")

df_ifr <- 
  data.frame(#df$Study, 
             df$Median_Age, 
             summary(fit, "ifr")$summary[, c("2.5%", "mean", "98%")]) %>% 
  setNames(c("age", "q025", "mean", "q975")) %>%
  mutate(key = "Fitted IFR (95% interval)")

```

```{r ifr-plot, fig.cap = "IFR as a function of age. Narrower ribbon corresponds to the 95% posterior interval of average across all included studies (tau parameter in the meta-analysis model), while the wider band takes into account heterogeneity (tau and sigma). Lines are means. Red points are model estimates of mean IFRs in partciular studies, with bars representing 95% posterior intervals. Panel A is untransformed data. Panel B shows the same data on log 10 scale.", fig.height = 10, fig.width = 8}


gg <- df_rep %>% 
  group_by(age) %>%
  mutate(mean_draw = inv_logit(mean_draw), rep_draw = inv_logit(rep_draw)) %>%
  summarise(mean = mint(mean_draw), stat = mint_nm, rep = mint(rep_draw),
            .groups = "keep") %>%
  gather(key, value, -age, -stat) %>%
  spread(stat, value) %>%
  mutate(key = factor(key, levels = c("mean", "rep"), 
                      labels = c("Mean over included studies (tau + beta*x)", 
                                 "Replication (N(tau + beta*x, sigma^2))"))) %>%
  ggplot(aes(x=age, y = mean, ymin = q025, ymax = q975, lty = key, fill = key)) +
  geom_ribbon(alpha = .25, fill = "black") +
  geom_line(color = "black") +
  geom_point(data = df_ifr, color = "red", show.legend=FALSE) +
  geom_errorbar(data = df_ifr, color = "red", show.legend=FALSE) +
  scale_fill_grey() +
  guides(fill = FALSE) +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  guides(colour = FALSE) +
  ylab("Infection fatality rate") +
  coord_cartesian(xlim = c(0.1, 80), ylim = c(1e-6, .2))

gridExtra::grid.arrange(grobs = list(gg + ggtitle("A") + theme(legend.position = "none"), 
                                     gg + scale_y_log10() + ggtitle("B")), 
                        ncol = 1)
```

```{r}

```

## Sensitivity analyses

<!-- __WW: I WILL WORK ON THIS IN NOV-DEC 2020. ALL 4 OF THESE ARE ESSENTIAL FOR PUBLICATION (to make sure our assumptions are not distorting the results in unexpected ways)__ -->

Planned sensitivity analyses include:

* Exclusion of small studies and test & trace data
* Median age: exclusion of 80+ population (non-linear behaviour on logit IFR?)
    + Could also check exclusion of children and teenagers, due to imprecise prevalence numbers
* Median age: different method of age imputation
* Model including time

\pagebreak

# Risk reduction in healthy individuals

We now turn our attention to the question of how much a human challenge trial designer could reduce the mortality risk by using simple screening methods, as discussed in the main paper.

```{r open-safely-data}
open_safely <- read_excel("data/OpenSafely_Counts.xls")

stan_df <- open_safely %>% 
  filter(!is.na(Fatalities)) %>% 
  filter(`Healthy Weight` == 0) %>%
  mutate(f = ifelse(Fatalities == "<=5", "5", Fatalities)) %>%
  mutate(f = as.numeric(f)) %>%
  mutate(p = f/Population) %>%
  select(-`Healthy Weight`, -Fatalities) %>%
  rename(no_com = `No Comorbidities`)

# Divide into healthy population and pop with comorbidities:
open_safely_df_wide <- stan_df %>% 
  select(-p) %>%
  pivot_wider(names_from = no_com, values_from = c(Population, f)) %>%
  mutate(n_como = Population_0 - Population_1,
         f_como = f_0 - f_1) %>%
  rename(n_healthy = Population_1, 
         n_all = Population_0,
         f_all = f_0,
         f_healthy = f_1)

open_safely_df_long <- open_safely_df_wide %>%
  gather(group, value, -Age_min, -Age_max, -Gender) %>%
  separate(group, sep = "_", c("stat", "group")) %>%
  spread(stat, value)
```

```{r, eval = FALSE}
n1 <- 2530792
p1 <- 13/n1
n2 <- 1788907
p2 <- 6/n2
f1 <- 13
f2 <- 6

x1 <- rbinom(100000, n1, p1)/n1
x2 <- rbinom(100000, n2, p2)/n2
quantile(x1/x2, c(.025, .975))
rr1_ci <- mean(x1/x2)

rr <- log(f1*n2/(f2*n1))
se <- sqrt((n1-f1)/(n1*f1) + (n2-f2)/(n2*f2))
rr_ci <- c(exp(rr - 2*se), exp(rr + 2*se))
```

Data for this section has been provided by OpenSAFELY (<https://opensafely.org/>) and was used by @williamson_factors_2020 to characterise Covid-19 mortality risk factors for 10,926 Covid-19 deaths in England. We group the total of 21,444,863 individuals into a total population and a lower-risk sub-population, defined as non-smoker, non-obese and without the comoribidities reported in the OpenSAFELY study\footnote{"asthma, other chronic respiratory disease, chronic heart disease, diabetes mellitus, chronic liver disease, chronic neurological diseases, common autoimmune diseases (Rheumatoid Arthritis (RA), Systemic Lupus Erythematosus (SLE) or psoriasis), solid organ transplant, asplenia, other immunosuppressive conditions, cancer, evidence of reduced kidney function, and raised blood pressure or a diagnosis of hypertension"}, most notably respiratory and cardiovascular diseases and type I diabetes.
For brevity we refer to the population without one of the pre-defined comorbidities as "healthy". In contrast to the cited publication, we include records of individuals under 18 in our assessment. Counts grouped by age are presented in Table \@ref(tab:open-safely-tab). Complete data (broken down by gender) are in Table \@ref(tab:open-safely-all) at the end of the document.

```{r}
como_df <- stan_df %>%
  group_by(Age_min, no_com) %>%
  summarise(p=sum(Population), f=sum(f), .groups = "keep") %>%
  mutate(m = f/p) 
```

```{r open-safely-age, fig.width = 5, fig.height = 3, warning = F, fig.cap = "Fatality rates as a function of age in OpenSAFELY data. Fatality rate is zero in the 0-10 and 10-20 age groups."}
open_safely_df_long %>%
  mutate(group = factor(group, levels = c("all", "como", "healthy"),
                        labels = c("All", "With comorbidities", "W/o comorbidities"))) %>%
  group_by(Age_min, group) %>%
  summarise_if(is.numeric, sum) %>%
  mutate(m = f/n) %>%
  ggplot(aes(x = Age_min + 5, y=m, 
             # group = status, 
             color = group)) +
  geom_point() +
  geom_line() +
    xlab("Age") + ylab("Fatality rate") +
  theme_minimal() +
  scale_y_log10() +
  theme(legend.position = "right", legend.direction = "vertical", 
        legend.title = element_blank())
```


As shown in Table \@ref(tab:open-safely-tab), for the age group of 20-29 the crude risk ratio (of general population vs the healthy subset only) is 1.53, but, due to low number of events in both healthy and general population, with a very wide 95% interval from 0.6 to 5.65.^[We obtain the interval using a simulation approach. Using normal approximation of log(RR) statistic we obtain a narrower 0.57 to 4.1, perhaps due to poor quality of approximation for rare events.] As data on relative risks in other age groups is clearly related to the relative risk in 20-29 age group, we use another meta-analysis model to improve our estimate. Additionally, relative risks are higher in women than in men -- something that we can account for in our model too.

In our modelling we make a strong assumption that infection rates in population with comorbidities are the same as in the general population. In other words, we assume that denominator for IFR is same in both populations. We then specify a generic partial pooling model of fatality rates (FR, defined as number of deaths in the entire population, without regards to infection status) such that

\begin{align}
\text{logit}(\text{FR}_k) & \sim \mathcal{N}(\alpha_{\text{age}_k} \text{comorb}_k + \beta \text{male}_k + \gamma_{\text{age}_k}), \\
\alpha_i & \sim \mathcal{N}(\mu, \sigma) \text{ for all } i,
\end{align}

where, for $k$-th observation, $\text{age}_k$ is the age group, and $\text{comorb}_k$ and $\text{male}_k$ are indicator variables. This means that each age group is assigned different "baseline" fatality rates.

Note that the assumption of FRs varying across age groups that we just mentioned differs from the model of age-specific IFRs in Section 2. This is because we hypothesised that infection rates (which are used as denominators in the IFR model of Section 2) will vary across age groups. This is borne out by Figure \@ref(fig:open-safely-age). 

```{r open-safely-tab}
como_df %>% 
  mutate(m = 1e05*m) %>%
  mutate(Age_min = paste(Age_min, "to", ifelse(Age_min == 70, "Inf", Age_min+9))) %>%
  gather(key, value, -Age_min, -no_com) %>% 
  pivot_wider(names_from = c(key, no_com), values_from = value) %>%
  mutate(rr = m_0/m_1) %>%
  kbl(col.names = c("Age group", "All", "Healthy", "All", "Healthy", "All", "Healthy", "RR"),
      caption = "Data from the OpenSAFELY database grouped by age.",
      booktabs = TRUE, 
      format.args = list(big.mark = ",")) %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Population" = 2, "Fatalities" = 2, "FR per 100k" = 2, " " = 1))
```





```{r open-safely-stan-data, eval = T}
stan_data <- 
  open_safely_df_long %>%
  filter(group != "all") %>% 
  with(list(
    N = nrow(.),
    # age = ifelse(stan_df$Age_min >= 20, (stan_df$Age_min - 20)/10, 0), #experimental
    # under20 = 1*(stan_df$Age_min < 20),
    age_group = as.numeric(factor(Age_min)), #experimental
    male = 1*(Gender == "M"),
    comorbidities = 1*(group == "como"),
    Npop = n,
    Nevents = f,
    Nages = max(Age_min/10 + 1))
  )
```

```{r, eval = FALSE}
# sm_como <- stan_model("rr_comorbidities_v3.stan")
# fit_como <- sampling(sm_como, data = stan_data, refresh = 0)
# saveRDS(fit_como, file = "output/como_stan_model.rds")

sm_como5 <- stan_model("rr_comorbidities_v5.stan")
fit_como5 <- sampling(sm_como5, data = stan_data, 
                      refresh = 0, iter = 5000, control = list(adapt_delta = .99, max_treedepth = 15))
saveRDS(fit_como5, file = "output/como_stan_model_v6.rds")
```

Summary of the main model parameters is as follows:

```{r}
fit_como <- readRDS(file = "output/como_stan_model_v6.rds")
alpha_exp <- exp(rstan::extract(fit_como, "alpha[3]")[[1]])
summary(fit_como, c("mu", "sigma", "alpha[3]", "beta", "gamma[3]"))$summary
```

```{r}
rr_df_all <- rstan::extract(fit_como, "theta")[[1]] %>% 
  as.data.frame() %>% setNames(1:32) %>% 
  mutate(sim = 1:n()) %>%
  gather(id, value, -sim) %>% 
  mutate(id = as.numeric(id)) %>%
  left_join(open_safely_df_long %>% 
              filter(group != "all") %>% 
              mutate(id = 1:n()), by = "id") %>%
  select(-id, -f) %>%
  pivot_wider(names_from = c(group, Gender), values_from = c(value,n)) %>% 
  mutate(theta_all = (n_como_F*value_como_F + n_como_M*value_como_M +
                        n_healthy_M*value_healthy_M + 
                        n_healthy_F*value_healthy_F)/(n_como_M + n_como_F + n_healthy_M + n_healthy_F),
         theta_healthy = (n_healthy_M*value_healthy_M + 
                        n_healthy_F*value_healthy_F)/(n_healthy_M + n_healthy_F)) %>%
  mutate(rr = theta_all/theta_healthy) 

rr_healthy <- rr_df_all$rr[rr_df_all$Age_min == 20]

rr_df <- rr_df_all %>%
  group_by(Age_min) %>%
  summarise(mean = mean(rr), lci = quantile(rr, .025), uci = quantile(rr, .975), 
            .groups = "keep") %>%
  column_to_rownames("Age_min")
```

We find that the mean risk ratio between population with comorbidities and healthy sub-population in 20-29 age group (exponent of $\alpha_3$ above) is `r mean(alpha_exp)`, with wide 95% uncertainty interval of `r quantile(alpha_exp, .025)` to `r quantile(alpha_exp, .975)`.^[Using simple models that assumed identical risk ratios in all age groups would lead to a mean RR of similar magnitude but a much less uncertain estimate, due to more rigid model assumptions; similarly, assuming some linear age structure on risks, such as in the main meta-analysis model above, would may lead to a different RR, but we do not think such an assumption is justified here. We do not include outputs of these models in this short write-up.]

Next, using the posterior samples we calculate the event rate in total population (i.e. $\theta\ast = (\theta_1 n_1 + \theta_2 n_2)/(n_1+n_2)$, where subscripts 1 and 2 are healthy and comorbid sub-populations) and then divide it by ratio in healthy population to obtain an estimate of risk reduction possible by selecting healthy volunteers only. The mean posterior value is `r rr_df["20","mean"]`, with 95% uncertainty interval from `r rr_df["20", "lci"]` to `r rr_df["20", "uci"]`. Due to use of Bayesian hierarchical model over many age groups, the uncertainty interval is much narrower than on the risk reduction factor calculated on 20-29 age group only.

To validate the model, we conducted a simple posterior predictive check for numbers of deaths in different age groups and genders. The graphical check is presented in Figure \@ref(fig:open-safely-ppc). Overall we find that the simple model has no problem with reproducing observed data.

```{r open-safely-ppc, fig.width = 8, fig.height = 7, fig.cap = "Comparison of posterior predictive numbers of deaths from the fitted Bayesian model (mean and 95% uncertainty intervals) with data inputs (circles). For each age grouping we have 4 estimates: male/female and healthy vs general population"}
open_safely_df_long %>%
  filter(group != "all") %>% 
  mutate(lci = summary(fit_como, "Nevent_ppc")$summary[,"2.5%"],
         estimate = summary(fit_como, "Nevent_ppc")$summary[,"mean"],
         uci = summary(fit_como, "Nevent_ppc")$summary[,"98%"]) %>%
  # mutate(lci = log(lci), estimate = log(estimate), uci = log(uci)) %>%
  mutate(group = ifelse(group == "como", "With comorbidities", "Healthy")) %>%
  mutate(Age_min = paste(Age_min, "to", ifelse(Age_min == 70, "Inf", Age_min+9))) %>%
  ggplot(aes(x = interaction(Gender,group), y = estimate, 
             color = Gender)) + 
  geom_point() +
  geom_point(aes(y = f), pch = 21) +
  geom_errorbar(aes(ymin = lci, ymax = uci, lty = group), width = 0) +
  facet_wrap(~ Age_min, scales = "free") +
  xlab("") + ylab("N deaths")+
  theme_minimal() +
  theme(legend.position = c(1, 0),
        legend.justification = c(1, 0),
        axis.text.x = element_blank())
```


\pagebreak 

# Conclusion and summary of results

```{r}
lci <- function(x, q=.95) quantile(x, (1-q)/2)
uci <- function(x, q=.95) quantile(x,  1 - ((1-q)/2))
# theta_min <- inv_logit(as.matrix(fit, "theta_k")[,which.min(theta_mean)])
# final_ifr <- theta_min/rr_healthy

# This uses fit and theta_mean objects defined above
output_df <- data.frame(
  # Stan model parameters (on logit scale)
  hypermean    = (rstan::extract(fit, "tau")[[1]]),
  hypersd      = (rstan::extract(fit, "sigma")[[1]]),
  beta         = (rstan::extract(fit, "beta")[[1]]), #effect per extra decade of age
  # Lowest theta in our sample: 
  # i.e. smallest fitted logit IFR (currently it's Belgium)
  theta_min    = (as.matrix(fit, "theta_k")[,which.min(theta_mean)]),
  # RR parameters from OpenSAFELY model (see derivation above)
  #ratio of mortality in healthy to general population
  rr_healthy_25 = rr_df_all$rr[rr_df_all$Age_min == 20],   
  rr_healthy_35 = rr_df_all$rr[rr_df_all$Age_min == 30]
) %>%
  mutate(
    rr_healthy_30   = rr_healthy_25/2 + rr_healthy_35/2, #weighted mean of 2 age groups
    # For each quantity we derive first using median of 25 years, then of 30 years
    metaanalysis_ifr_25     = inv_logit(hypermean),
    metaanalysis_ifr_30     = inv_logit(hypermean + .5*beta),
    metaanalysis_ifr_35     = inv_logit(hypermean + beta),
    replications_25 = inv_logit(rnorm(nsamples, hypermean, hypersd)),
    # replications_30 = inv_logit(rnorm(nsamples, hypermean + .5*beta, hypersd)),
    replications_35 = inv_logit(rnorm(nsamples, hypermean + beta, hypersd)),
    ifr_min_25      = inv_logit(theta_min),
    ifr_min_30      = inv_logit(theta_min + .5*beta),
    ifr_min_35      = inv_logit(theta_min + beta)
  ) %>%
  mutate(
    min_healthy_ifr_25 = ifr_min_25/rr_healthy_25,
    min_healthy_ifr_30 = ifr_min_30/rr_healthy_30,
    min_healthy_ifr_35 = ifr_min_35/rr_healthy_35,
    metaanalysis_healthy_ifr_25 = metaanalysis_ifr_25/rr_healthy_25,
    metaanalysis_healthy_ifr_35 = metaanalysis_ifr_35/rr_healthy_35,
  )

attach(output_df, warn.conflicts = FALSE)
# summary(output_df)

```

In conclusion, the implications of the model for the risk in healthy young subjects are as follows:

* We find that average IFR in 20-29 age group for the studies included in this analysis is `r mean(metaanalysis_ifr_25)` with 95% interval from `r lci(metaanalysis_ifr_25)` to `r uci(metaanalysis_ifr_25)`.
    + It is feasible that the mean IFR can be decreased as much as `r mean(exp(2*hypersd))`-fold ($2\sigma$ impact on the IFR according to hyper-SD parameter in the meta-analysis model). 
    + It is easy to argue that a HCT designer would be able to achieve IFR at least as low as within any of the large-scale studies included in our sample of populations. The smallest posterior mean for 20-29 year olds is `r inv_logit(min(theta_mean))`, fitted to data from `r names(theta_mean)[which.min(theta_mean)]`.
    + Extending the HCT population to also include 30-39 year olds would lead to mean IFR of `r mean(metaanalysis_ifr_30)` with 95% interval from `r lci(metaanalysis_ifr_30)` to `r uci(metaanalysis_ifr_30)`. Lowest mean IFR would then be `r mean(ifr_min_30)` (also in `r names(theta_mean)[which.min(theta_mean)]`).
* In healthy population (defined as lack of co-morbidities listed above), the average mortality risk in 20-29 year olds is `r mean(rr_healthy_25)` times lower than in the general population, with 95% uncertainty interval from `r lci(rr_healthy_25)` to `r uci(rr_healthy_25)`.
    + Our `r mean(rr_healthy_25)` estimate is a bit higher than the mean "crude" risk ratio of 1.53 because we use a Bayesian hierarchical model that synthesises evidence across all age groups. 
    + Expanding to 20-39 year olds, the risk in healthy sub-population would be `r mean(rr_healthy_30)` times lower than in the general population (95% interval from `r lci(rr_healthy_25)` to `r uci(rr_healthy_25)`).
* Combining the smallest posterior IFR for 20-29 year olds with our estimated fold-reduction due to excluding individuals with co-morbidities from the population would lead to a mean infection fatality risk of  `r mean(min_healthy_ifr_25)` with 95% Bayesian interval from `r lci(min_healthy_ifr_25)` to `r uci(min_healthy_ifr_25)`.
    + In 20-39 year old subjects the risk would be `r mean(min_healthy_ifr_30)` (`r lci(min_healthy_ifr_30)` to `r uci(min_healthy_ifr_30)`).

```{r output-csv}
write.csv(output_df, file = "output/bayesian-posteriors-shiny.csv")
```

\pagebreak

```{r prevalence-data, fig.cap = "Comparison of model-estimated prevalences (95% CI's reported by modelling studies) collected by @levin_assessing_2020 and our distributional assumptions: additional circles show 95% CIs recreated by assuming logit-normal distribution of prevalence. We group studies into 4 bands of mortality to mirror earlier figures. Please note that this approach produces discrepancies in a number of US estimates where the confidence intervals were skewed toward including 0. However, since we do not have access to source data, we decided to use the logit-normal assumption for all estimates. This assumption may have an effect of overestimating mortality risk in settings where prevalence was very low.", fig.height = 9.5, fig.width = 9.5, warning = FALSE}
df %>% 
  mutate(midpoint_u = logit_mean + logit_sd*1.96, midpoint_l = logit_mean - logit_sd*1.96) %>%
  mutate(Median_Age = ifelse(is.na(Median_Age), 0, Median_Age)) %>%
  mutate(deaths_cut = cut(Deaths/Population, c(-Inf, 1/1e06, 50/1e06, 500/1e06, Inf),
                          c("< 1 per million", "1-50 per million", "50-500 per million", "over 500 per million"))) %>%
  
  ggplot(aes(x=ir, xmax = ir_high, xmin=ir_low, y=interaction(Study, AgeGroup))) + 
  geom_point() + geom_errorbarh() +
  geom_point(aes(x = inv_logit(midpoint_l)), pch = 21) +
  geom_point(aes(x = inv_logit(midpoint_u)), pch = 21) +
  xlab("Infection rate (95% interval)") + ylab("") +
  facet_wrap(~ deaths_cut, ncol = 2, scales = "free") +
  scale_x_log10()

```

\pagebreak

```{r input-data-big}
df_tab <- all_data_xls %>% 
  arrange(Median_Age, Study) %>%
  select(Study, StudyScale, StudyType, EndDate, 
         AgeGroup, 
         Deaths, 
         Population, InfectionRate, infrate_ci95_high, infrate_ci95_low) %>%
  filter(!is.na(Deaths), !is.na(InfectionRate), !is.na(Population)) %>%
  # mutate(ir_95 = paste0(round(infrate_ci95_low, 1), ", ", round(infrate_ci95_high, 1))) %>%
  # select(-infrate_ci95_low, -infrate_ci95_high) %>%
  mutate(ifr = 1e05*Deaths/(Population*InfectionRate)) %>%
  mutate(infrate_ci95_low = round(infrate_ci95_low, 2)) %>%
  mutate(infrate_ci95_high = round(infrate_ci95_high, 2)) %>%
  mutate(InfectionRate = round(InfectionRate, 2)) %>%
  mutate(Deaths = round(Deaths)) %>%
  mutate(Population = round(Population)) 

write.csv(df_tab, file = '../ShinyApp/source_data.csv') # For the app.

kbl(df_tab,  longtable = TRUE, booktabs = TRUE,
      caption = "Complete table of inputs used by the meta-analysis model and crude IFR's.",
      col.names = c("Study location", "Scale", "Type", "End date", "Age", 
                    "Deaths", "N", "Mean", "2.5%", "97.5%", "IFR/100k"))%>%
  kable_styling(latex_options = c("repeat_header")) %>%
  add_header_above(c(" " = 7, "Infection rate (%)" = 3, " " = 1)) %>%
  landscape()
  
```

\pagebreak

# References
