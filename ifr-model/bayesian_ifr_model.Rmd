---
title: "Bayesian model for COVID IFR"
author: "Witold WiÄ™cek for 1 Day Sooner"
date: "Last updated `r Sys.Date()`"
output: 
  bookdown::pdf_document2:
    toc: false
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(baggr)
library(tidyverse)
library(readxl)
library(knitr)
library(kableExtra)
# Stan stuff:
library(rstan)
set.seed(1990)
rstan_options(auto_write = TRUE)
sm <- stan_model("ifr_with0.stan")
options(mc.cores = 4, digits = 2)
```


# Introduction

This is a short document describing a Bayesian model for synthesising information on many infection fatality rates (IFRs) into a single estimate that can be made specific to certain age groups or adjusted by co-morbidity status. The analysis presented here is a form of Bayesian meta-analysis, in that our primary objective is to weigh sources of evidence in a way that captures both variability (heterogeneity across different settings) and uncertainty.

Our ultimate objective is to characterise risks in a particular setting, population and time, in a way that is useful to understanding risks of human challenge trials (HCTs). Therefore, as a minimum, we want to incorporate variability into our prediction. Even better would be to understand how different factors can drive heterogeneity. Indeed, _a priori_, we can hypothesise that the three main drivers of differences in IFRs are time-specific, population-specific and otherwise country-specific. 

The role of time may be due to new treatments, improvements over time in our ability to treat Covid-19 or selection pressures which may lead to more benign versions of the virus.
Country-specific or location-specific factors in IFR data may be driven by under-reporting, health care factors (including access to health care services) or underlying distributions of known risk factors. Additionally, some unknown risk factors (e.g. genetic) may also be operating, in which case controlling for age and co-morbidities will be not sufficient to account for cross-location differences. 

To address these drivers of differences in observed IFRs we develop a Bayesian model and apply it to publicly available summary data on IFRs from multiple countries and contexts, with particular focus on the impact of age.



# Evidence synthesis model

What follows is an adaptation of typical methods of Bayesian evidence synthesis to analysis of IFRs. IFR is the ratio of deaths to infections in a given population. Early estimates, e.g. by @verity_estimates_2020, place it at over 0.6% globally. However, it's evident from data that IFR is orders of magnitude higher in particular high risk groups, especially in the elderly, than in the general population. Such relationship seems to be consistent across different countries.

We can use Bayesian meta-analysis models to account for the fact that different population studies at different times have different average probability of events. We use hierarchical modelling framework to assume that the context-specific estimates of $IFR_i$ (measured in different settings, with some uncertainty) are linked through some common parameters.

The most straight-forward and "canonical" way to implement such a Bayesian model is by modelling log odds of the event.^[It is also possible to work with $IFR_i$ parameters and treat them as derived from Beta distribution with some "hyperparameters" $\alpha$ and $\beta$ of Beta distribution, as done by e.g. @carpenter_hierarchical_2016. That approach, however, does not offer an easy way of modelling impact of covariates (e.g. age and co-morbidities) on the rates.]
@deeks_issues_2002 present a general treatment. Note, that for very rare events the odds of mortality are very similar to probability of mortality, but we model events on odds scale as a good "generic" approach to modelling binary data (in this case death following infections). Another advantage of such a model is that it can use either individual-level or summary data and work with covariates (such as gender, age, time of the study, co-morbidities), captured as odds ratios or risk ratios^[If only summary data are available, covariates can be defined as study level distributions (e.g. % male)]. 

Basic models for this type of analysis of binary data can be implemented using existing statistical analysis packages (see, for example, _metafor_ package in R or _baggr_  by @wiecek_baggr_2020), by treating IFR as a logit-normal parameter to meta-analyse. However, note that when no deaths are observed, analysis of IFR (equal to observed deaths divided by modelled infections) is problematic. Therefore we propose a "custom" model that built in Stan which treats deaths and _prevalences_ (rather than the IFRs) as data. 

Let $d_k$ denote observed deaths for data point $k$ and assume that logit of prevalence $p_k$ in the population of $n_k$ subjects is obtained from some model. We can then write:

\begin{align}
d_k & \sim \text{Binomial}(n_k, p_kIFR_k) \\
\text{logit}(p_k) & \sim \mathcal{N}(\mu^{(p)}_k, \sigma^{(p)}_k)
\end{align}

where $\sigma^{(p)}_k$ and $\mu^{(p)}_k$ are parameters derived from the existing models of prevalence. The $k$ data points collected can span many locations (studies); we denote them by $\text{loc}_k$ and the total number of locations by $N_{loc}$.

In this model we can also account for various covariates impacting the IFRs, such as age groups (which we identify with median age of the population being studied, $\text{MedianAge}_k$). We code them in a design matrix $X$. To center our $X$ at the value of interest in our model (risk in 20-30 year olds), we use a transformation `MedianAge/10 - 2.5` to construct our matrix $X$. We denote all of the covariates using a design matrix $X$ and denote by $N_p$ the number of columns in $X$. 
We assume the impact on IFR is on logit scale, same as in the "canonical" logistic models of binary data that we mentioned above:

$$
\text{logit}(IFR_k) = \theta_{\text{loc}_k} + X\beta
$$
where $\theta$ is an $N_{loc}$-dimensional vector of location-specific (random) effects on IFR and $\beta$ is $N_p$ dimensional vector of (fixed) covariate effects.

We implement our model in Stan and assume weakly informative priors on all parameters, with prior for $\tau$ centered at 1 death per 10,000 cases. 

```
model {
  //Uncertain prevalence estimates:
  logit_prevalence ~ normal(mean_prevalence, sd_prevalence);
  //Likelihood of mortality:
  obs_deaths ~ binomial(population, prevalence .* ifr);
  //Hierarchical component of the model (location-specific theta):
  theta_k ~ normal(tau, sigma);

  //Priors:
  tau   ~ normal(logit(.0001), 5);
  sigma ~ normal(0, 10);
  beta  ~ normal(0, 10);
}
```







# Data on age-specific mortality risk

```{r read-data, eval = F}
# Several different datasets.
NBER_IFR_Benchmark_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xlsx',1)
#Places: Belgium. Geneva, Indiana, New York, Spain, Sweden
NBER_IFR_US_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xlsx',2, skip=1)
names(NBER_IFR_US_Studies)[6:7]<-c('Infect 95_lower','Infect 95_upper')
names(NBER_IFR_US_Studies)[10:11]<-c('IFR_95_lower','IFR_95_upper')

# NBER_All_Studies <- read_excel('data/NBER_IFR_Meta_Dataset.xls',5)
```

```{r read-joint-data}
all_data_xls <- read_excel("data/1DS_Meta_Dataset_ww.xls") %>%
                           # col_types = c("text", "text", "date", "date", rep("text", 4), "numeric", "text", rep("numeric", 11))) %>%
  rename(Study = StudyName) %>%
  # Use imputed deaths and population sizes where neeeded
  mutate(Deaths = ifelse(is.na(Deaths) & !is.na(`Imputed Deaths`), `Imputed Deaths`, Deaths)) %>%
  mutate(Population = ifelse(is.na(Population) & !is.na(`Imputed Population`), `Imputed Population`, Population))
```


```{r}
logit <- function(x) log(x/(1-x))
inv_logit <- function(x) exp(x)/(1+exp(x))

ifr_joint <- all_data_xls %>%
  group_by(Study) %>%
  mutate(ir = InfectionRate/100, 
         ir_low = infrate_ci95_low/100, 
         ir_high = infrate_ci95_high/100) %>%
  select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
  mutate(dataset = "Global")

# ifr_global <- NBER_IFR_Benchmark_Studies %>%
#   group_by(Study) %>%
#   mutate(ir = InfectionRate/100, 
#          ir_low = infrate_ci95_low/100, 
#          ir_high = infrate_ci95_high/100) %>%
#   select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
#   mutate(dataset = "Global")
# 
# ifr_us <- NBER_IFR_US_Studies %>%
#   filter(!is.na(AgeGroup)) %>%
#   group_by(Study) %>%
#   mutate(ir = `Infection Rate (%)`/100, 
#          ir_low = `Infect 95_lower`/100, 
#          ir_high = `Infect 95_upper`/100) %>%
#   select(Study, AgeGroup, Median_Age, Deaths, Population, ir, ir_low, ir_high) %>%
#   mutate(dataset = "United States")
```



```{r prep-data}
# df <- rbind(ifr_global, ifr_us) %>%
df <- ifr_joint %>%
  mutate(logit_sd = ifelse(ir_low != 0, 
                         (logit(ir_high) - logit(ir_low))/(2*1.96), 
                         (logit(ir_high) - logit(ir))/1.96)) %>%
  mutate(logit_mean = logit(ir)) %>%
  filter(!is.na(Deaths), !is.na(logit_sd), !is.na(logit_mean), !is.na(Population))
```

```{r}
df_age <- df %>% mutate(age = gsub("\\+", "-Inf", AgeGroup)) %>%
  separate(age, c("ageMin", "ageMax")) %>%
  select(Study, ageMin, ageMax) 
good_data_pts <- sum(df_age$ageMin < 30 & df_age$ageMax > 20)
```

We used estimates originally collected by @levin_assessing_2020 to construct the first version of analysis dataset, which we then supplemented with more values extracted from other studies. __Write-up of data collection here.__ The input data into our model consists of deaths (treated as known) and prevalences (treated as logit-distributed parameter with known mean and SD) in all reported age groups in all studies^[This basic approach exaggerates uncertainty, as we treat different 95% intervals reported in the study as uncorrelated.]. 

```{r}
data_ns <- df %>% group_by(Study) %>% tally() %>% pull(n)
```

All of input data are given in Table \@ref(tab:input-data-tab). The analysis dataset contains `r nrow(df)` data points from `r length(data_ns)` studies, each containing between `r min(data_ns)` and `r max(data_ns)` different age groups. We made only minimal modifications to source data, by 1) imputing the values in Italian study (__David to describe__?), 2) imputing population size in Maranhao (as ratio of the reported number of infections and the mean infection rate) which were not reported and 3) assuming that uncertainty in prevalence 0-29 age group in Iceland is same as in the 30-39 age group since data were missing.

Our model treats number of Covid-attributable deaths as measured without error (due to lack of data) but accounts for uncertainty in infection rates, which are always model-based estimated extracted from various available data sources. We assume that logits of prevalence estimates from available studies are normally distributed, which seems to reproduce majority of data perfectly, see Figure \@ref(fig:prevalence-data) in the Supplement.

For each study we construct a median age scalar defined as __David to detail this: for now leaving blank as it might change with sensitivity analyses__.

Our approach of regressing on the median age and use of all available data (rather than the subset of data available in younger adults only) is necessitated by data limitations: out of `r nrow(df_age)` data points comprising age-specific estimates of prevalence (or IFR) and counts of deaths, `r good_data_pts` contain individuals aged 20-30 who are of primary interest to us. However, the populations are mixed with regards to age, with typical age groupings such as 19-49, 20-49, 20-39, 0-49 used instead. In fact, we find only one estimate out of `r good_data_pts` that is entirely specific to the 20-29 age group (Brazilian state of Maranhao). 

```{r stan-data}
mm <- model.matrix(ir ~ Study + Median_Age, data = df)
stan_data <- list(
  X = matrix(df$Median_Age/10 - 2.5, nrow(df), 1),
  N = nrow(df), 
  Np = 1,
  Nloc = length(unique(df$Study)),
  loc = as.numeric(as.factor(df$Study)),
  mean_prevalence = df$logit_mean,
  sd_prevalence = df$logit_sd,
  population = as.integer(df$Population),
  obs_deaths = as.integer(df$Deaths))
```


# Results: age-specific risk of Covid mortality


```{r run-stan-model, eval = FALSE}
fit <- sampling(sm, data = stan_data, control = list(max_treedepth = 15), 
                iter = 5000, refresh = 0)
saveRDS(fit, file = "output/main_stan_model.rds")
```

```{r}
fit <- readRDS("output/main_stan_model.rds")
```

There were no issues with convergence of the Bayesian model. We set number of iterations to 5,000 and used 4 chains, with `max_treedepth` option set to 15. There were no divergent transitions and effective sample size was greater than `r round(min(summary(fit)$summary[,"n_eff"]))` for all of `r length(summary(fit)$summary[,"n_eff"]) - 1` modeled parameters (this number includes fitted prevalences, IFRs, $\theta$'s and their transformations into/from logit scales). For the three main parameters in the model we obtained the following:

```{r}

print(fit, c("tau", "sigma", "beta"))
```

The mean coefficient of beta `r round(mean(c(as.matrix(fit, "beta[1]"))), 2)` corresponds to `r mean(exp(mean(c(as.matrix(fit, "beta[1]")))))`-fold increase in mortality risk following an infection per each extra decade of age (95% uncertainty interval is `r paste(round(quantile(exp((c(as.matrix(fit, "beta[1]")))), c(.025, .975)),2),collapse = "-")`).

From these parameters we can predict average risks for subjects of any given age $x$, by using the posterior distribution of $\tau + (10x + 2.5) \beta$ (where 2.5 and 10 refer to the transformation that we applied to `MedianAge` inputs).



## Average infection fatality risk in young subjects

```{r}
hypermean <- (rstan::extract(fit, "tau")[[1]])
hypersd <- (rstan::extract(fit, "sigma")[[1]])
nsamples <- length(hypermean)
hyperifr <- inv_logit(hypermean)
replications <- inv_logit(rnorm(nsamples, hypermean, hypersd))
```

Since we centered our `MedianAge` at 25 years in constructing our matrix $X$, we can now obtain model-estimated risk for a typical HCT population (aged 20 to 30, with median 25) by ignoring the $\beta$ coefficient and examining $\tau$ and $\sigma$ only. We find that the average IFR for this group (equal to $\frac{\exp{(\tau)}}{\exp{(1 + \tau)}}$) is `r mean(hyperifr)` (with 95% interval from `r quantile(hyperifr, .025)` to `r quantile(hyperifr, .975)`). That means, on average, slightly under 2 deaths per 10,000 infections in the studied datasets.


## Heterogeneity in IFRs

However, there is a considerable variability in IFRs across different locations/dataset that we should consider. To take into account parameter $\sigma$, we can generate draws from the $\mathcal{N}(\tau, \sigma^2)$ distribution, corresponding to a hypothetical IFR in a new source of data. 95% interval for such model runs from `r quantile(replications, .025)` to `r quantile(replications, .975)`. Since the model works a logistic scale, another way of interpreting the across-dataset variability is reporting the fold-impact of $\sigma$ on the mean IFR; here, we obtain on average a `r mean(exp(2*hypersd))`-fold increase (decrease) in IFR per $2\sigma$ increase (decrease).

The lower end of the 95% interval, `r quantile(replications, .025)`, is not extreme given input data, where the "crude" mean IFR (based on mean prevalence only) is below 7 per 10,000 for all data except for South Florida, and as low as 0 for some countries that did not record deaths (Belgium, New Zealand, Korea, Iceland) in various age groups including 20-29 year olds or 1.4 per 10,000 in Utah, in the population aged 19-44. (Please refer to Table \@ref(tab:input-data-tab) for complete list of inputs.)

```{r, eval = FALSE}
df %>% filter(Median_Age > 10, Median_Age < 35) %>% 
  select(Study, AgeGroup, Deaths, Population, ir) %>%
  mutate(crude_ifr = Deaths/(Population*ir))
```

```{r}
theta_mean <- summary(fit, "theta_k")$summary[,"mean"]
names(theta_mean) <- levels(as.factor(df$Study))
```

We can assess this heterogeneity by inspecting the distribution of random effects in the model transformed into IFRs, 
i.e. the inverse logit transformation $\theta$ parameters. 
The largest (posterior mean) IFR value of $\theta$ is `r inv_logit(max(theta_mean))` in `r names(theta_mean)[which.max(theta_mean)]`.
The smallest posterior mean for 20-29 year olds is `r inv_logit(min(theta_mean))` in `r names(theta_mean)[which.min(theta_mean)]`.




## Predictive checks for the model

```{r}
df_cov <- data.frame(study = df$Study, 
           observed = df$Deaths,
           summary(fit, "ppc_deaths")$summary) %>% 
  mutate(coverage975 = (observed + .1) > X2.5. & observed < X98.) %>%
  mutate(coverage50 = (observed + .1) > X25. & observed < X75.) %>% 
  summarise(n = n(), coverage975 = sum(coverage975), coverage50 = sum(coverage50))
```

We constructed posterior predictive distributions for number of deaths in each of the inputs by using the `generated quantities` functionality of Stan. Figure \@ref(fig:obs-est-deaths) compares the posterior means and 95% intervals with observed deaths. Out of `r df_cov$n` observations that were used to fit the model, `r df_cov$coverage975` were within 95% intervals of the posterior predictive distributions. We observed the largest discrepancies occurred in Spanish data. Overall, we conclude that the simple binomial model we used here is flexible enough to capture both age-specific risk increases and heterogeneity in IFRs across settings/countries. 

```{r obs-est-deaths, fig.width = 10, fig.height = 10, fig.cap = "Comparison of model estimates (black) with observed mortality (red), compared on logarithmic scale. Bars are 95% posterior interval; point is the mean. For better clarity, we grouped the plot into four panels according to observed mortality. X axes on each panel differ. For many low-risk populations no deaths were reported: we indicate this by plotting a red point on the left-hand side of the panel plot.", warning = FALSE}
data.frame(study = df$Study, 
           age = df$AgeGroup,
           observed = df$Deaths,
           summary(fit, "ppc_deaths")$summary) %>% 
  mutate_if(is.numeric, function(x) x/df$Population) %>%
  mutate(deaths_cut = cut(observed, c(-Inf, 1/1e06, 50/1e06, 500/1e06, Inf),
                          c("< 1 per million", "1-50 per million", "50-500 per million", "over 500 per million"))) %>%
  ggplot(aes(y=interaction(study, age))) + 
  geom_point(aes(x = mean)) + 
  geom_errorbarh(aes(xmin = X2.5., xmax = X98.)) + 
  geom_point(aes(x = observed), color = "red") + 
  facet_wrap(~deaths_cut, ncol = 2, scales = "free") +
  scale_x_log10() +
  xlab("Covid-attributable mortality") + ylab("")
```

```{r}
hypermean <- (rstan::extract(fit, "tau")[[1]])
hypersd <- (rstan::extract(fit, "sigma")[[1]])
beta <-  (rstan::extract(fit, "beta[1]")[[1]])


hyperifr <- inv_logit(hypermean)
replications <- inv_logit(rnorm(nsamples, hypermean, hypersd))

df_rep <- data.frame(age = rep(seq(1, 85), each = 5e04)) %>%
  mutate(hypermean = sample(hypermean, nrow(.), replace = T),
         hypersd = sample(hypersd, nrow(.), replace = T),
         beta = sample(beta, nrow(.), replace = T)) %>%
  mutate(mean_draw = hypermean + beta*(age/10 - 2.5)) %>%
  mutate(rep_draw  = rnorm(nrow(.), mean_draw, hypersd)) %>%
  select(age, mean_draw, rep_draw)

mint <- function(x) c(quantile(x, .025), mean(x), quantile(x, .975))
mint_nm <- c("q025", "mean", "q975")

df_ifr <- 
  data.frame(#df$Study, 
             df$Median_Age, 
             summary(fit, "ifr")$summary[, c("2.5%", "mean", "98%")]) %>% 
  setNames(c("age", "q025", "mean", "q975")) %>%
  mutate(key = "Fitted IFR (95% interval)")

```

```{r ifr-plot, fig.cap = "IFR as a function of age. Narrower ribbon corresponds to the 95% posterior interval of average across all included studies (tau parameter in the meta-analysis model), while the wider band takes into account heterogeneity (tau and sigma). Lines are means. Red points are model estimates of mean IFRs in partciular studies, with bars representing 95% posterior intervals. Panel A is untransformed data and panel B is same data on log 10 scale.", fig.height = 10, fig.width = 8}


gg <- df_rep %>% 
  group_by(age) %>%
  mutate(mean_draw = inv_logit(mean_draw), rep_draw = inv_logit(rep_draw)) %>%
  summarise(mean = mint(mean_draw), stat = mint_nm, rep = mint(rep_draw),
            .groups = "keep") %>%
  gather(key, value, -age, -stat) %>%
  spread(stat, value) %>%
  mutate(key = factor(key, levels = c("mean", "rep"), 
                      labels = c("Mean over included studies (tau + beta*x)", 
                                 "Replication (N(tau + beta*x, sigma^2))"))) %>%
  ggplot(aes(x=age, y = mean, ymin = q025, ymax = q975, lty = key, fill = key)) +
  geom_ribbon(alpha = .25, fill = "black") +
  geom_line(color = "black") +
  geom_point(data = df_ifr, color = "red", show.legend=FALSE) +
  geom_errorbar(data = df_ifr, color = "red", show.legend=FALSE) +
  scale_fill_grey() +
  guides(fill = FALSE) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  guides(colour = FALSE) +
  ylab("Infection fatality rate") +
  coord_cartesian(xlim = c(0.1, 80), ylim = c(1e-6, .2))

gridExtra::grid.arrange(grobs = list(gg + ggtitle("A") + theme(legend.position = "none"), 
                                     gg + scale_y_log10() + ggtitle("B")), 
                        ncol = 1)
```

```{r}

```

## Robustness checks

* Exclusion of small studies and test & trace data
* Median age: exclusion of 80+
* Median age: different method of age imputation
* Model with time

\pagebreak



# How much lower is the risk in healthy individuals?

We now turn our attention to the question of how much a human challenge trial designer could reduce the mortality risk by using simple screening methods.

```{r open-safely-data}
open_safely <- read_excel("data/OpenSafely_Counts.xls")

stan_df <- open_safely %>% 
  filter(!is.na(Fatalities)) %>% 
  filter(`Healthy Weight` == 0) %>%
  mutate(f = ifelse(Fatalities == "<=5", "5", Fatalities)) %>%
  mutate(f = as.numeric(f)) %>%
  mutate(p = f/Population) 
```

```{r, eval = FALSE}
n1 <- 2530792
p1 <- 13/n1
n2 <- 1788907
p2 <- 6/n2
f1 <- 13
f2 <- 6

x1 <- rbinom(100000, n1, p1)/n1
x2 <- rbinom(100000, n2, p2)/n2
quantile(x1/x2, c(.025, .975))
rr1_ci <- mean(x1/x2)

rr <- log(f1*n2/(f2*n1))
se <- sqrt((n1-f1)/(n1*f1) + (n2-f2)/(n2*f2))
rr_ci <- c(exp(rr - 2*se), exp(rr + 2*se))
```

Data for this section has been provided by OpenSAFELY (<https://opensafely.org/>) and was used by @williamson_factors_2020 to characterise Covid-19 mortality risk factors for 10,926 Covid-19 deaths in England. We group the total of 21,444,863 individuals into high and low risk groups as follows: __Definition of co-morbiditiy goes here (David/team).__ For brevity we define population without one of the pre-defined comorbidities as "healthy". In contrast to the cited publication, we include records of individuals under 18 in our assessment. Counts grouped by age are presented in Table \@ref(tab:open-safely-tab). Complete data (broken down by gender) are in \@ref(tab:open-safely-all) at the end of the document.

```{r}
como_df <- stan_df %>%
  filter(`Healthy Weight` == 0) %>%
  group_by(Age_min, `No Comorbidities`) %>%
  summarise(p=sum(Population), f=sum(f), .groups = "keep") %>%
  mutate(m = f/p) 
```

```{r, fig.width = 3, fig.height = 3}
como_df %>%
  rename(status = `No Comorbidities`) %>%
  mutate(status = ifelse(status, 
                                "No comorbidities", "All individuals")) %>%
  ggplot(aes(x = Age_min + 5, y=log(m), 
             group = status, color = status)) +
  geom_point() +
  geom_line() +
    xlab("Age") + ylab("log(case fatality rate)") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank() )
```


As shown in Table \@ref(tab:open-safely-tab), for the age group of 20-29 the crude risk ratio is 1.53, but, due to low number of events in both healthy and general population, with a very wide 95% interval from 0.6 to 5.65.^[We obtain the interval using a simulation approach. Using normal approximation of log(RR) statistic we obtain a narrower 0.57 to 4.1, perhaps due to poor quality of approximation for rare events.] As data on relative risks in other age groups is clearly related to the relative risk in 20-29 age group, we use another meta-analysis model to improve our estimate. Additionally, relative risks are higher in women than in men -- something that we can account for in our model too.

In our modelling we make a strong assumption that infection rates in population with comorbidities are the same as in the general population. In other words, we assume that IFR is proportional to CFR in the same way in both populations. We then specify a generic partial pooling model of CFR such that

\begin{align}
\text{logit}(\text{CFR}_k) & \sim \mathcal{N}(\alpha_{\text{age}_k} \text{comorb}_k + \beta \text{male}_k + \gamma_{\text{age}_k}), \\
\alpha_i & \sim \mathcal{N}(\mu, \sigma) \text{ for all } i;
\end{align}

where, for $k$-th observation, $\text{age}_k$ is the age group, with each age group given different "baseline" CFR, and $\text{comorb}_k$ and $\text{male}_k$ are indicator variables.


```{r open-safely-tab}

como_df %>% 
  mutate(m = 1e05*m) %>%
  mutate(Age_min = paste(Age_min, "to", ifelse(Age_min == 70, "Inf", Age_min+9))) %>%
  rename(nocom = `No Comorbidities`) %>% 
  gather(key, value, -Age_min, -nocom) %>% 
  pivot_wider(names_from = c(key, nocom), values_from = value) %>%
  mutate(rr = m_0/m_1) %>%
  kbl(col.names = c("Age group", "All", "Healthy", "All", "Healthy", "All", "Healthy", "RR"),
      caption = "Data from the OpenSAFELY database grouped by age.",
      booktabs = TRUE, 
      format.args = list(big.mark = ",")) %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Population" = 2, "Fatalities" = 2, "CFR per 100k" = 2, " " = 1))
```





```{r open-safely-stan-data, eval = T}
stan_data <- list(
  N = nrow(stan_df),
  age = ifelse(stan_df$Age_min >= 20, (stan_df$Age_min - 20)/10, 0), #experimental
  male = 1*(stan_df$Gender == "M"),
  comorbidities = 1*(stan_df$`No Comorbidities` == 0),
  overweight = 1*(stan_df$`Healthy Weight` == 0),
  under20 = 1*(stan_df$Age_min < 20),
  Npop = stan_df$Population,
  Nevents = stan_df$f)

stan_data$age_group <- stan_df$Age_min/10 + 1
stan_data$Nages <- max(stan_df$Age_min/10 + 1)
```

```{r, eval = FALSE}
# sm_como <- stan_model("rr_comorbidities_v3.stan")
# fit_como <- sampling(sm_como, data = stan_data, refresh = 0)
# saveRDS(fit_como, file = "output/como_stan_model.rds")

sm_como5 <- stan_model("rr_comorbidities_v5.stan")
fit_como5 <- sampling(sm_como5, data = stan_data, 
                      refresh = 0, iter = 5000, control = list(adapt_delta = .99, max_treedepth = 15))
saveRDS(fit_como5, file = "output/como_stan_model.rds")
```

Summary of the main model parameters is as follows:

```{r}
fit_como <- readRDS(file = "output/como_stan_model.rds")
alpha_exp <- exp(rstan::extract(fit_como, "alpha[3]")[[1]])
summary(fit_como, c("mu", "sigma", "alpha[3]", "beta", "gamma[3]"))$summary
```

We find that the mean risk ratio between general population and healthy sub-population in 20-29 age group (exponent of $\alpha_3$) is `r mean(alpha_exp)`, with 95% interval from `r quantile(alpha_exp, .025)` to `r quantile(alpha_exp, .975)`. Please note that the uncertainty in this estimate is large (capturing our uncertainty about influence of data from the other age groups on RR in 20-29 age group), but less than in the estimate based purely on 20-29 year olds. ^[Using simple models that assumed identical risk ratios in all age groups would result in mean RR of 3 but much less uncertain estimate, due to more rigid model assumptions; similarly, assuming some linear age structure on risks such as in the main meta-analysis model above, would also lead to RR of about 3. We do not include outputs of these models in this short write-up.]

We conducted a simple posterior predictive check for numbers of deaths in different age groups and genders. The graphical check is presented in Figure \@ref(fig:open-safely-ppc). Overall we find that the simple model has no problem with reproducing observed data.

```{r open-safely-ppc, fig.width = 7, fig.height = 7, fig.cap = "Comparison of posterior predictive numbers of deaths from the fitted Bayesian model (mean and 95% intervals) with data inputs (circles). For each age grouping we have 4 estimates: male/female and healthy (`No.Comorbidities` equal to 1) vs general population (0)"}
data.frame(  stan_df,
  lci = summary(fit_como, "Nevent_ppc")$summary[,"2.5%"],
  estimate = summary(fit_como, "Nevent_ppc")$summary[,"mean"],
  uci = summary(fit_como, "Nevent_ppc")$summary[,"98%"]) %>%
  # mutate(lci = log(lci), estimate = log(estimate), uci = log(uci)) %>%
  mutate(No.Comorbidities = factor(No.Comorbidities)) %>%
  ggplot(aes(x = interaction(Gender,No.Comorbidities), y = estimate, 
             color = Gender)) + 
  geom_point() +
  geom_point(aes(y = f), pch = 21) +
  geom_errorbar(aes(ymin = lci, ymax = uci, lty = No.Comorbidities), width = 0) +
  facet_wrap(~ Age_min, scales = "free") +
  xlab("") + ylab("N deaths")+
  theme(legend.position = c(1, 0),
        legend.justification = c(1, 0))
```


# Conclusion and summary of results

```{r}
lci <- function(x, q=.95) quantile(x, (1-q)/2)
uci <- function(x, q=.95) quantile(x,  1 - ((1-q)/2))
# hyperifr
# replications
# alpha_exp
theta_min <- inv_logit(as.matrix(fit, "theta_k")[,which.min(theta_mean)])
final_ifr <- theta_min/alpha_exp
```

In conclusion:

* We find that average IFR in 20-29 age group for the studies included in this analysis is `r mean(hyperifr)` with 95% interval from `r lci(hyperifr)` to `r uci(hyperifr)`.
    + It is feasible that the mean IFR can be decreased as much as `r mean(exp(2*hypersd))`-fold ($2\sigma$ impact on the IFR according to hyper-SD parameter in the meta-analysis model). 
    + It is easy to argue that a HCT designer would be able to achieve IFR at least as low as within any of the large-scale studies included in our sample of populations. The smallest posterior mean for 20-29 year olds is `r inv_logit(min(theta_mean))`, fitted to data from `r names(theta_mean)[which.min(theta_mean)]`.
* Reduction possible from only analysing healthy population (defined as lack of co-morbidities listed above) is `r mean(alpha_exp)` with 95% interval from `r lci(alpha_exp)` to `r uci(alpha_exp)`. This estimate is obtained under a strong assumption that CFRs in general population are the same as in the healthy sub-population.
* Combining the smallest posterior IFR for 20-29 year olds with our estimated fold-reduction due to excluding individuals with co-morbidities from the population would lead to a mean infection fatality risk of  `r mean(final_ifr)` with 95% Bayesian interval from `r lci(final_ifr)` to `r uci(final_ifr)`.


\pagebreak

```{r prevalence-data, fig.cap = "Comparison of model-estimated prevalences (95% CI's reported by modelling studies) collected by @levin_assessing_2020 and our distributional assumptions: additional circles show 95% CIs recreated by assuming logit-normal distribution of prevalence. We group studies into 4 bands of mortality to mirror earlier figures. Please note that this approach produces discrepancies in a number of US estimates where the confidence intervals were skewed toward including 0. However, since we do not have access to source data, we decided to use the logit-normal assumption for all estimates. This assumption may have an effect of overestimating mortality risk in settings where prevalence was very low.", fig.height = 9.5, fig.width = 9.5, warning = FALSE}
df %>% 
  mutate(midpoint_u = logit_mean + logit_sd*1.96, midpoint_l = logit_mean - logit_sd*1.96) %>%
  mutate(Median_Age = ifelse(is.na(Median_Age), 0, Median_Age)) %>%
  mutate(deaths_cut = cut(Deaths/Population, c(-Inf, 1/1e06, 50/1e06, 500/1e06, Inf),
                          c("< 1 per million", "1-50 per million", "50-500 per million", "over 500 per million"))) %>%
  
  ggplot(aes(x=ir, xmax = ir_high, xmin=ir_low, y=interaction(Study, AgeGroup))) + 
  geom_point() + geom_errorbarh() +
  geom_point(aes(x = inv_logit(midpoint_l)), pch = 21) +
  geom_point(aes(x = inv_logit(midpoint_u)), pch = 21) +
  xlab("Infection rate (95% interval)") + ylab("") +
  facet_wrap(~ deaths_cut, ncol = 2, scales = "free") +
  scale_x_log10()

```

\pagebreak

```{r input-data-tab}
df_tab <- all_data_xls %>% 
  arrange(Median_Age, Study) %>%
  select(Study, StudyScale, StudyType, EndDate, 
         AgeGroup, 
         Deaths, 
         Population, InfectionRate, infrate_ci95_high, infrate_ci95_low) %>%
  filter(!is.na(Deaths), !is.na(InfectionRate), !is.na(Population)) %>%
  # mutate(ir_95 = paste0(round(infrate_ci95_low, 1), ", ", round(infrate_ci95_high, 1))) %>%
  # select(-infrate_ci95_low, -infrate_ci95_high) %>%
  mutate(ifr = 1e05*Deaths/(Population*InfectionRate)) %>%
  mutate(infrate_ci95_low = round(infrate_ci95_low, 2)) %>%
  mutate(infrate_ci95_high = round(infrate_ci95_high, 2)) %>%
  mutate(InfectionRate = round(InfectionRate, 2)) %>%
  mutate(Deaths = round(Deaths)) %>%
  mutate(Population = round(Population)) 

kbl(df_tab,  longtable = TRUE, booktabs = TRUE,
      caption = "Complete table of inputs used by the meta-analysis model and crude IFR's.",
      col.names = c("Study location", "Scale", "Type", "End date", "Age", 
                    "Deaths", "N", "Mean", "2.5%", "97.5%", "IFR/100k"))%>%
  kable_styling(latex_options = c("repeat_header")) %>%
  add_header_above(c(" " = 7, "Infection rate (%)" = 3, " " = 1)) %>%
  landscape()
  
```

\pagebreak

```{r open-safely-all}
stan_df %>%
  filter(`Healthy Weight` == 0) %>%
  group_by(Age_min, `No Comorbidities`, Gender) %>%
  summarise(p=sum(Population), f=sum(f), .groups = "keep") %>%
  mutate(m = f/p) %>%
  mutate(m = 1e05*m) %>%
  mutate(Age_min = paste(Age_min, "to", ifelse(Age_min == 70, "Inf", Age_min+9))) %>%
  rename(nocom = `No Comorbidities`) %>% 
  gather(key, value, -Age_min, -nocom, -Gender) %>% 
  pivot_wider(names_from = c(key, nocom), values_from = value) %>%
  arrange(Gender) %>%
  mutate(rr = m_0/m_1) %>%
  kbl(col.names = c("Age group", "Gender", "All", "Healthy", "All", "Healthy", "All", "Healthy", "RR"),
      caption = "Data from the OpenSAFELY database grouped by age and broken down by gender.",
      booktabs = TRUE, 
      format.args = list(big.mark = ",")) %>%
  kable_styling() %>%
  add_header_above(c(" " = 2, "Population" = 2, "Fatalities" = 2, "CFR per 100k" = 2, " " = 1)) %>%
  group_rows("Female", 1, 8) %>%
  group_rows("Male", 9, 16)
```

# References
